#!/usr/bin/env python
import os
import sys
import json
import argparse
import subprocess
import logging as lg
from os.path import basename, exists

from azkaban import Job, Project
from azkaban.remote import Session


formatter = lg.Formatter('%(asctime)s %(levelname)s %(name)s %(message)s', '%d/%m/%y %H:%M:%S')
ch = lg.StreamHandler(sys.stdout)
ch.setFormatter(formatter)
logger = lg.getLogger('azkaban_submit_job')
logger.setLevel(lg.INFO)
logger.addHandler(ch)


def run_shell_command(cmd, description, cwd=None, shell=False):
    if not cwd:
        cwd = os.getcwd()
    p = subprocess.Popen(cmd, cwd=cwd, stdout=subprocess.PIPE, shell=shell)
    stdout, stderr = p.communicate()
    logger.info('%s: %s' % (description, stdout))
    if stderr:
        logger.error(stderr)
        exit(-1)
    else:
        return stdout.strip()


def get_camus_version(path):
    path = os.path.join(path, 'camus-shopify')
    logger.info('Retrieving Camus version from %s' % path)
    cmd = "mvn org.apache.maven.plugins:maven-help-plugin:2.1.1:evaluate -Dexpression=project.version | grep -Ev '(^\[|Download\w+:)'"
    return run_shell_command(cmd, 'Retrieved Camus version', path, True)


def main():
    repo_root = os.getcwd()
    hadoop_classpath = '/etc/camus:/etc/hadoop/conf:/u/cloudera/parcels/CDH/lib/hadoop/libexec/../../hadoop/lib/*:/u/cloudera/parcels/CDH/lib/hadoop/libexec/../../hadoop/.//*:/u/cloudera/parcels/CDH/lib/hadoop/libexec/../../hadoop-hdfs/./:/u/cloudera/parcels/CDH/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/u/cloudera/parcels/CDH/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/u/cloudera/parcels/CDH/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/u/cloudera/parcels/CDH/lib/hadoop/libexec/../../hadoop-yarn/.//*:/u/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/./:/u/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/lib/*:/u/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/.//*'
    camus_version = get_camus_version(repo_root)
    camus_jar = 'camus-shopify-%s.jar' % camus_version
    azkaban_auth = json.load(open(os.path.join(repo_root, 'camus-shopify', 'azkaban.json')))

    project = Project('Camus')
    project.add_file(os.path.join(repo_root, 'camus-shopify', 'target', camus_jar), '%s' % camus_jar)
    project.add_job('Camus', Job({'java.class': 'com.linkedin.camus.etl.kafka.CamusJob',
                                          'failure.emails': 'yagnik.khanna@shopify.com',
                                          'main.args': '-P /u/apps/camus/shared/camus.properties',
                                          'type': 'javaprocess',
                                          'jvm.args': '-Xms1G -Xmx1G -DHADOOP_USER_NAME=deploy -Dlog4j.configuration=file:/u/apps/camus/shared/log4j.xml',
                                          'classpath': '%s:%s' % (hadoop_classpath, camus_jar)
    }))

    logger.info('Building zip file')
    project.build('camus.zip', True)
    logger.info('Connecting to Azkaban site')
    session = Session(azkaban_auth['server'])
    session.user = azkaban_auth['user']
    session._refresh(azkaban_auth['password'])

    logger.info('Uploading zip file')
    session.upload_project('Camus', 'camus.zip')
    logger.info('Successfully uploaded Camus zip file.')

    session.schedule_workflow('Camus', 'Camus', date='01/01/2014', time="12,01,AM,UTC", period="1h", concurrent=False)
    logger.info('Successfully scheduled Camus flow.')

if __name__ == '__main__':
    main()
